:noaudio:
:scrollbar:
:data-uri:
:toc2:
:linkattrs:

= Circuit Breaker Lab

== Lab Overview

This exercise shows how to inject faults and test the resiliency of your application. Istio provides a set of failure recovery features that can be taken advantage of by the services in an application. Features include:

    Timeouts
    Bounded retries with timeout budgets and variable jitter between retries
    Limits on number of concurrent connections and requests to upstream services
    Active (periodic) health checks on each member of the load balancing pool
    Fine-grained circuit breakers (passive health checks) – applied per instance in the load balancing pool

Together, these features enable the service mesh to tolerate failing nodes and prevent localized failures from cascading instability to other nodes.

== Goals

In this lab, you will learn how to:

* Implement the pool ejection resilience strategy to increase the overall availability
* Leverage the circuit breaker pattern to avoid multiple concurrent requests to an instance


[NOTE]
._Before Start_
====
You should have NO virtualservice nor destinationrule (in tutorial namespace) istioctl get virtualservice istioctl get destinationrule if so run:

----
cd ~/rhte-msa-and-service-mesh/

./scripts/clean.sh $OCP_TUTORIAL_PROJECT
----

== Update Application Code

In this section, you will update the CatalogVerticle to expose additional endpoints for testing

. Edit the file with the following commands:
+
----
cd ~/rhte-msa-and-service-mesh/catalog/java/vertex

vi src/main/java/com/redhat/developer/demos/catalog/CatalogVerticle.java
----

. Uncomment the line `router.get("/").handler(this::timeout);`

. Save the file and exit vi using `ESC` + `:wq`

. Build the service with the following commands:
+
----
mvn clean package

docker build -t example/catalog:v2 .
----

. Deploy Catalog service version 2 
+
----
oc delete pod -l app=catalog-service,version=v2
----
+
* Why the delete pod? Based on the Deployment configuration, Kubernetes/OpenShift will recreate the pod, based on the new docker image as it attempts to keep the desired replicas available.

. You can see both versions of the catalog pods running using `oc get pods`:
+
----
oc get pods -l app=catalog

NAME                                 READY     STATUS    RESTARTS   AGE
catalog-v1-60483540-9snd9     2/2       Running   0          12m
catalog-v2-2815683430-vpx4p   2/2       Running   0          15s
----

== Pool Ejection
Pool ejection or outlier detection is a resilience strategy that takes place whenever we have a pool of instances/pods to serve a client request. If the request is forwarded to a certain instance and it fails (e.g. returns a 50x error code), then Istio will eject this instance from the pool for a certain sleep window. In our example the sleep window is configured to be 15s. This increases the overall availability by making sure that only healthy pods participate in the pool of instances.

First, you need to insure you have a destinationrule and virtualservice in place to send traffic to the services. 

. Configure the rules to split the traffic 50/50.
+
----
cd ~/rhte-msa-and-service-mesh/

istioctl create -f istiofiles/destination-rule-catalog-v1-v2.yml -n $OCP_TUTORIAL_PROJECT
istioctl create -f istiofiles/virtual-service-catalog-v1_and_v2_50_50.yml -n $OCP_TUTORIAL_PROJECT
----

. Scale number of instances of v2 deployment
+
----
oc scale deployment catalog-v2 --replicas=2 -n $OCP_TUTORIAL_PROJECT
----

* Wait for all the pods to be in the ready state.

=== Test behavior without failing instances

. Send some requests to the gateway service:
+
----
./scripts/run.sh
----

* You will see the load balancing 50/50 between the two different versions of the catalog service. And within version v2, you will also see that some requests are handled by one pod and some requests are handled by the other pod.
+
----
TODO
----

=== Test behavior with failing instance and without pool ejection

. Get the name of the pods for catalog v2
+
----
oc get pods -l app=catalog,version=v2
----

* You should see:
+
----
catalog-v2-2036617847-hdjv2   2/2       Running   0          1h
catalog-v2-2036617847-spdrb   2/2       Running   0          7m
----

Now we’ll get into one the pods and add some erratic behavior on it. 

. Get one of the pod names from your system and replace on the following command accordingly:
+
----
oc exec -it $(oc get pods|grep catalog-v2|awk '{ print $1 }'|head -1) -c catalog /bin/bash
----

. You will be inside the application container of your pod catalog-v2-2036617847-spdrb. Now execute:
+
----
curl localhost:8080/misbehave
exit
----
* This is a special endpoint that will make our application return only `503` errors.

. Send some requests to the gateway service:
+
----
./scripts/run.sh
----
+
* You’ll see that whenever the pod catalog-v2-2036617847-spdrb receives a request, you get a 503 error:
+
----
TODO
----

=== Test behavior with failing instance and with pool ejection

. Now let’s add the pool ejection behavior:
+
----
istioctl replace -f istiofiles/destination-rule-recommendation_cb_policy_pool_ejection.yml -n $OCP_TUTORIAL_PROJECT
----

. Send some requests to the gateway service:
+
----
./scripts/run.sh
----
+
* You will see that whenever you get a failing request with 503 from the pod catalog-v2-2036617847-spdrb, it gets ejected from the pool, and it doesn’t receive any more requests until the sleep window expires - which takes at least 15s.:
+
----
TODO
----

== Ultimate resilience with retries, circuit breaker, and pool ejection



====

== References

* https://openshift.com[Red Hat OpenShift, window="_blank"]
* https://learn.openshift.com/servicemesh[Learn Istio on OpenShift, window="_blank"]
* https://istio.io[Istio Homepage, window="_blank"]