:noaudio:
:scrollbar:
:data-uri:
:toc2:
:linkattrs:

= Dynamic Routing with Istio

== What is a Service Mesh?

As microservices-based applications become more prevalent, both the number of
and complexity of their interactions increases. Up until now much of the burden
of managing these complex microservices interactions has been placed on the
application developer, with different or non-existent support for microservice
concepts depending on language and framework.

The service mesh concept pushes this responsibility to the infrastructure, with
features for traffic management, distributed tracing and observability, policy
enforcement, and service/identity security, freeing the developer to focus on
business value. In this hands-on session you will learn how to apply some of
these features to a simple polyglot microservices application running on top of
OpenShift using Istio, an open platform to connect, manage, and secure
microservices.

== What is Istio?

Istio is an open platform to connect, manage, and secure microservices. Istio
provides an easy way to create a network of deployed services with load
balancing, service-to-service authentication, monitoring, and more, without
requiring any changes in application code. OpenShift can automatically inject a
special sidecar proxy throughout your environment to enable Istio management for
your application. This proxy intercepts all network communication between your
microservices microservices, and is configured and managed using Istioâ€™s control
plane functionality -- not your application code!

== Lab Overview

There are three microservices in this lab and they are chained together in the following sequence:

`gateway -> partner -> catalog`

In this lab you'll dynamically alter routing between the services using Istio.

== Goals

In this lab, you will learn how to:

* Inject sidecar proxies into applications which form a service mesh
* Configure a service mesh to dynamically route and shape traffic to and from services

== Deploy Catalog service version 2 (`v2`)

We can experiment with Istio routing rules by deploying a second version of the catalog
service.

. Edit Java source code to show v2 message
+
----
cd ~/rhte-msa-and-service-mesh/catalog/java/vertx

vi src/main/java/com/redhat/developer/demos/catalog/CatalogVerticle.java
----

. In the file `CatalogVerticle.java`, update this line to say `v2`
+
----
private static final String RESPONSE_STRING_FORMAT = "catalog v2 from '%s': %d\n";
----

. Save the file and exit vi.

. Build the service with the following commands:
+
----
mvn clean package

docker build -t example/catalog:v2 .
----
+
NOTE: The "v2" tag during the Docker build is significant.

. Deploy Catalog service version 2 
+
----
oc apply -f <(istioctl kube-inject -f ../../kubernetes/Deployment-v2.yml) -n $OCP_TUTORIAL_PROJECT
----
+
* This second deployment file `Deployment-v2.yml` will label the service correctly.

. You can see both versions of the `catalog` pods running with the following command:
+
----
oc get pods -l app=catalog
----
+
* Expect to see the following:
+
----
NAME                          READY     STATUS    RESTARTS   AGE
catalog-v1-6b576ffcf8-g6b48   2/2       Running   0          31m
catalog-v2-7764964564-hj8xl   2/2       Running   0          49s
----
+
* By default, Istio will round-robin incoming requests to the `catalog` Service
so that both `v1` and `v2` pods get equal amounts of traffic.

. Make sure your environment variable for $GATEWAY_URL is still set.
+
----
echo $GATEWAY_URL
----

. Test the gateway service
+
----
curl $GATEWAY_URL
----
+
* You will likely see:
+
----
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 2
----
+
* Where `6b576ffcf8-g6b48` is the pod running `v1` and the `2` is the number of times you hit the endpoint.

. Make another request to the gateway service
+
----
gateway => partner => catalog v2 from '7764964564-hj8xl': 1
----
+
* Where `7764964564-hj8xl` is the pod running `v2` and the `1` is basically the number of times you hit the endpoint.

* By default you get round-robin load-balancing when there is more than one Pod behind a Service

. Send severals to the gateway service. 
+
----
~/rhte-msa-and-service-mesh/scripts/run.sh
----
+
* The `run.sh` script will loop and send 10 requests to the gateway service.

* You should see:
+
----
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 4
gateway => partner => catalog v2 from '7764964564-hj8xl': 3
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 5
gateway => partner => catalog v2 from '7764964564-hj8xl': 4
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 6
gateway => partner => catalog v2 from '7764964564-hj8xl': 5
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 7
gateway => partner => catalog v2 from '7764964564-hj8xl': 6
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 8
gateway => partner => catalog v2 from '7764964564-hj8xl': 7
----
+
* Approximately half of the requests above go to `v1` and the other half to `v2`.

* The default Kubernetes/OpenShift behavior is to round-robin load-balance across all
available pods behind a single Service. 

. Scale up the number of pods for the `catalog-v2` pod:
+
----
oc scale --replicas=2 deployment/catalog-v2
----

. Now let's send in 10 requests
+
----
~/rhte-msa-and-service-mesh/scripts/run.sh
----

* Now, you will see *double* the number of requests to `v2` than for `v1`:
+
----
gateway => partner => catalog v2 from '7764964564-hj8xl': 8
gateway => partner => catalog v2 from '7764964564-d8qwp': 1
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 9
gateway => partner => catalog v2 from '7764964564-hj8xl': 9
gateway => partner => catalog v2 from '7764964564-d8qwp': 2
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 10
gateway => partner => catalog v2 from '7764964564-hj8xl': 10
gateway => partner => catalog v2 from '7764964564-d8qwp': 3
gateway => partner => catalog v1 from '6b576ffcf8-g6b48': 11
gateway => partner => catalog v2 from '7764964564-hj8xl': 11
----

. Scale back to a single pod for the `catalog-v2` deployment:
+
----
oc scale --replicas=1 deployment/catalog-v2
----

. Run the test again and confirm that the requests are split evenly between `v1` and `v2`.

== Send all traffic to `catalog:v2`

_Route rules_ control how requests are routed within an Istio service mesh.

Requests can be routed based on the source and destination, HTTP header fields, and weights associated with individual service versions. For example, a route rule could route requests to different versions of a service.

In addition to the usual OpenShift object types like `BuildConfig`, `DeploymentConfig`,
`Service` and `Route`, you also have new object types installed as part of Istio like `RouteRule`. Adding these objects to the running OpenShift cluster is how you configure routing rules for Istio.

. Route all traffic to `v2`:
+
----
cd ~/rhte-msa-and-service-mesh

istioctl create -f istiofiles/destination-rule-catalog-v1-v2.yml -n $OCP_TUTORIAL_PROJECT
istioctl create -f istiofiles/virtual-service-catalog-v2.yml -n $OCP_TUTORIAL_PROJECT
----

. Test the `gateway` service again - all requests should end up talking to
`catalog:v2`:
+
----
scripts/run.sh
----
+
* You should only see v2 being returned.
+
----
TODO
----

== Send all traffic to `catalog:v1`

. Now let's move everyone to `v1`:
+
----
oc replace -f istiofiles/virtual-service-catalog-v1.yml -n $OCP_TUTORIAL_PROJECT
----
+
NOTE: We use `oc replace` instead of `oc create` since we are overlaying the previous rule

. Now let's send in 10 requests:
+
----
scripts/run.sh
----
+
* Notice how all requests now to go `v1`.
+
----
TODO
----

. Remove the route rules to get back to default round-robin distribution
of requests.
+
----
oc delete -f istiofiles/virtual-service-catalog-v1.yml -n $OCP_TUTORIAL_PROJECT
----

. Now let's send in 10 requests:
+
----
scripts/run.sh
----
+
* Traffic should be equally split once again between v1 and v2.
+
----
TODO
----

== Smart routing based on user's web browser

Istio can perform smart routing based on the user's web browser. For example, you can send all users of the Safari web browser to catalog service v2. The users of the Firefox browser are routed to catalog service v1.

This is accomplished by checking the request headers for `user-agent`. The "user-agent" header is added to OpenTracing baggage in the Gateway service. From there it is automatically propagated to all downstream services. To enable automatic baggage propagation all intermediate services have to be instrumented with OpenTracing. The baggage header for user agent has following form baggage-user-agent: <value>.

. Set up the routing to all catalog service v1
+
----
istioctl create -f istiofiles/destination-rule-catalog-v1-v2.yml -n $OCP_TUTORIAL_PROJECT

istioctl create -f istiofiles/virtual-service-catalog-v1.yml -n $OCP_TUTORIAL_PROJECT
----


. Now add a rule to route Safari users to catalog service v2
+
----
istioctl replace -f istiofiles/virtual-service-safari-catalog-v2.yml -n tutorial
----
+
* Based on these settings, Safari users will only see v2 responses from catalog. Note, this also applies to Chrome on the Mac since it includes Safari in the string. Users of the Firefox browser, it should only see v1 responses from catlog.

. Simulate web browser requests using the curl command. This is for Safari users
+
----
curl -A Safari $GATEWAY_URL
----

* You should see a response from the v2 service.

. Run a similar test for Firefox users
+
----
curl -A Firefox $GATEWAY_URL
----

* You should see a response from the v1 service.

. Let's clean up by removing the Safari rule.
+
----
istioctl delete -f istiofiles/destination-rule-catalog-v1-v2.yml -n tutorial

istioctl delete -f istiofiles/virtual-service-safari-catalog-v2.yml -n tutorial
----

== Use a Canary Deployment to slowly rollout `v2`

Canary Deployment scenario: push v2 into the cluster but slowly send end-user traffic to it, if you continue to see success, continue shifting more traffic over time.

. Create the virtualservice that will send 90% of requests to v1 and 10% to v2:
+
----
istioctl create -f istiofiles/virtual-service-catalog-v1_and_v2.yml -n $OCP_TUTORIAL_PROJECT
----

. Now let's send in 10 requests:
+
----
scripts/run.sh
----
+
You should see only 1 request to `v2`, and 9 requests (90%) to `v1`. In reality you may get
2 requests as our sample size is low, but if you invoked
it 10 million times you should get approximately 1 million requests to `v2`.

. Now let's move it to a 75/25 split:
+
----
istioctl replace -f istiofiles/virtual-service-catalog-v1_and_v2_75_25.yml -n $OCP_TUTORIAL_PROJECT
----

. And issue 10 more requests:
+
----
scripts/run.sh
----
+ 
* Now you should see 2 or 3 requests (~25%) going to `v2`. This process can be continued (and automated), slowly migrating
traffic over to the new version as it proves its worth in production over time.

==

. Remove the route rules before moving on:
+
----
scripts/clean.sh $OCP_TUTORIAL_PROJECT
----

== Congratulations!

In this lab you learned how to deploy microservices to form a _service mesh_ using Istio.
You also learned how to do traffic shaping and routing using _Route Rules_ which instruct
the Istio sidecar proxies to distribute traffic according to specified policy.

== References

* https://openshift.com[Red Hat OpenShift, window="_blank"]
* https://learn.openshift.com/servicemesh[Learn Istio on OpenShift, window="_blank"]
* https://istio.io[Istio Homepage, window="_blank"]